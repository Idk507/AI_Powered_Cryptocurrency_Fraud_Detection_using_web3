{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import time\n",
    "from datetime import datetime, timedelta\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.metrics import accuracy_score, classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the simulated historical data\n",
    "file_path = \"transaction_dataset.csv\"\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# Drop irrelevant columns (adjust column names if necessary)\n",
    "df = df.drop(columns=['Unnamed: 0', 'Index', 'Address'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define target and features\n",
    "y = df['FLAG']  # Assuming 'FLAG' is the target indicating bot activity (1 = Bot, 0 = Legitimate)\n",
    "X = df.drop(columns=['FLAG'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Feature Engineering for Bot Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def feature_engineering_for_bot_detection(df):\n",
    "    \"\"\"\n",
    "    Feature engineering to capture bot behavior characteristics:\n",
    "    1. Transaction Timing Consistency\n",
    "    2. Unusual Transaction Amounts\n",
    "    3. Pattern Consistency in Transactions\n",
    "    \"\"\"\n",
    "    # Feature 1: Transaction Timing Consistency\n",
    "    # (Assumes the CSV has a column 'Time Diff between first and last (Mins)')\n",
    "    if 'Time Diff between first and last (Mins)' in df.columns:\n",
    "        df['Transaction Time Diff'] = df['Time Diff between first and last (Mins)']\n",
    "    else:\n",
    "        df['Transaction Time Diff'] = 0\n",
    "\n",
    "    # Feature 2: Unusual Transaction Amounts\n",
    "    # Bots typically send similar amounts.\n",
    "    if set(['avg val sent', 'avg val received']).issubset(df.columns):\n",
    "        df['Transaction Amount Variance'] = df[['avg val sent', 'avg val received']].std(axis=1)\n",
    "    else:\n",
    "        df['Transaction Amount Variance'] = 0\n",
    "\n",
    "    # Feature 3: Pattern Consistency\n",
    "    if 'Unique Sent To Addresses' in df.columns:\n",
    "        df['Unique Sent Addresses'] = df['Unique Sent To Addresses']\n",
    "    else:\n",
    "        df['Unique Sent Addresses'] = 0\n",
    "\n",
    "    # Bot Activity Indicator (for demo purposes)\n",
    "    df['Bot Activity Indicator'] = (\n",
    "        df['Transaction Time Diff'] * df['Transaction Amount Variance'] * df['Unique Sent Addresses']\n",
    "    )\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Apply feature engineering for bot detection on historical data\n",
    "df = feature_engineering_for_bot_detection(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build and Train the Model Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop(columns=['FLAG'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify numerical and categorical columns from the training set\n",
    "numerical_cols = X.select_dtypes(include=['int64', 'float64']).columns.tolist()\n",
    "categorical_cols = X.select_dtypes(include=['object']).columns.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Build and store the list of training columns (order matters)\n",
    "training_columns = X.columns.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Preprocessing pipelines for numerical and categorical features\n",
    "numerical_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='median')),\n",
    "    ('scaler', StandardScaler())\n",
    "])\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "    ('onehot', OneHotEncoder(handle_unknown='ignore'))\n",
    "])\n",
    "preprocessor = ColumnTransformer(transformers=[\n",
    "    ('num', numerical_transformer, numerical_cols),\n",
    "    ('cat', categorical_transformer, categorical_cols)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the complete pipeline\n",
    "pipeline = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('classifier', RandomForestClassifier(random_state=42))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "pipeline.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the model\n",
    "y_pred = pipeline.predict(X_test)\n",
    "test_accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"\\nTest Accuracy: {:.4f}\".format(test_accuracy))\n",
    "print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Real-Time Bot Detection Simulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def align_features_for_real_time(df_sim):\n",
    "    \"\"\"\n",
    "    Ensure that the simulation DataFrame has exactly the same columns (and order)\n",
    "    as in the training data. For any missing column, we add a default value:\n",
    "      - For numerical features: 0\n",
    "      - For categorical features: 'Unknown'\n",
    "    \"\"\"\n",
    "    # Loop over all training columns\n",
    "    for col in training_columns:\n",
    "        if col not in df_sim.columns:\n",
    "            if col in numerical_cols:\n",
    "                df_sim[col] = 0\n",
    "            else:\n",
    "                df_sim[col] = 'Unknown'\n",
    "    # Reorder columns to match training data\n",
    "    df_sim = df_sim[training_columns]\n",
    "    return df_sim\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def simulate_real_time_transaction():\n",
    "    \"\"\"\n",
    "    Simulate a single real-time transaction with raw data.\n",
    "    Some raw columns are used in our historical feature engineering.\n",
    "    \"\"\"\n",
    "    transaction_data = {\n",
    "        'Sent tnx': random.randint(1, 10),\n",
    "        'Received Tnx': random.randint(1, 10),\n",
    "        'avg val sent': random.uniform(0.01, 5.0),\n",
    "        'avg val received': random.uniform(0.01, 5.0),\n",
    "        'Unique Sent To Addresses': random.randint(1, 20),\n",
    "        'Unique Received From Addresses': random.randint(1, 20),\n",
    "        'Time Diff between first and last (Mins)': random.uniform(1, 120),\n",
    "        'Timestamp': datetime.now()\n",
    "    }\n",
    "    return transaction_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_engineering_for_real_time_bot_detection(transaction_data, previous_data=None):\n",
    "    \"\"\"\n",
    "    Generate features for real-time bot detection based on transaction data.\n",
    "    This function computes a few derived features and then aligns the result\n",
    "    with the training feature set.\n",
    "    \"\"\"\n",
    "    # Compute derived features from the raw transaction data\n",
    "    transaction_frequency = transaction_data['Sent tnx'] + transaction_data['Received Tnx']\n",
    "    average_sent_amount = transaction_data['avg val sent']\n",
    "    average_received_amount = transaction_data['avg val received']\n",
    "    unique_sent_addresses = transaction_data['Unique Sent To Addresses']\n",
    "    \n",
    "    # Compute Transaction Time Consistency based on previous transaction timestamps\n",
    "    if previous_data is not None:\n",
    "        time_diff = (transaction_data['Timestamp'] - previous_data['Timestamp']).total_seconds() / 60.0\n",
    "    else:\n",
    "        time_diff = 0\n",
    "\n",
    "    # Compute the amount variance for the current transaction (using sent and received amounts)\n",
    "    transaction_amount_variance = np.std([average_sent_amount, average_received_amount])\n",
    "    \n",
    "    # Build a features dictionary.\n",
    "    # Note: We include only a subset of features; all other features from training will be added as defaults.\n",
    "    features = {\n",
    "        'Transaction Frequency': transaction_frequency,\n",
    "        'Average Sent Amount': average_sent_amount,\n",
    "        'Average Received Amount': average_received_amount,\n",
    "        'Unique Sent Addresses': unique_sent_addresses,\n",
    "        # For this simulation, we use our computed time difference as \"Transaction Time Consistency\"\n",
    "        'Transaction Time Consistency': time_diff,\n",
    "        'Transaction Time Diff': time_diff,  # to mimic the historical feature\n",
    "        'Transaction Amount Variance': transaction_amount_variance,\n",
    "        'Bot Activity Indicator': transaction_frequency * transaction_amount_variance * unique_sent_addresses,\n",
    "        # Optionally, you could add more simulated values here if desired.\n",
    "    }\n",
    "    \n",
    "    features_df = pd.DataFrame([features])\n",
    "    \n",
    "    # Align simulated features with training columns\n",
    "    features_df = align_features_for_real_time(features_df)\n",
    "    \n",
    "    return features_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def real_time_bot_detection(num_transactions=10, delay=2):\n",
    "    \"\"\"\n",
    "    Simulate real-time monitoring of incoming transactions for bot detection.\n",
    "    \"\"\"\n",
    "    previous_data = None  # Used for computing time differences between transactions\n",
    "    print(\"\\n--- Starting Real-Time Bot Detection Simulation ---\")\n",
    "    \n",
    "    for i in range(num_transactions):\n",
    "        transaction_data = simulate_real_time_transaction()\n",
    "        transaction_df = feature_engineering_for_real_time_bot_detection(transaction_data, previous_data)\n",
    "        \n",
    "        # Predict using the trained model\n",
    "        # (Note: The pipeline expects exactly the same features as in training.)\n",
    "        bot_prob = pipeline.predict_proba(transaction_df)[0, 1]\n",
    "        prediction = pipeline.predict(transaction_df)[0]\n",
    "        \n",
    "        print(f\"\\nTransaction {i + 1}:\")\n",
    "        print(f\"Predicted Bot Activity Probability: {bot_prob:.4f}\")\n",
    "        if prediction == 1:\n",
    "            print(\"⚠️ Bot Detected! Stopping transaction.\")\n",
    "        else:\n",
    "            print(\"Transaction appears legitimate. Proceeding with processing.\")\n",
    "        \n",
    "        previous_data = transaction_data  # Update for next iteration\n",
    "        time.sleep(delay)\n",
    "    \n",
    "    print(\"\\n--- Simulation Completed ---\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test Accuracy: 0.9888\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      0.99      1533\n",
      "           1       1.00      0.95      0.97       436\n",
      "\n",
      "    accuracy                           0.99      1969\n",
      "   macro avg       0.99      0.98      0.98      1969\n",
      "weighted avg       0.99      0.99      0.99      1969\n",
      "\n",
      "\n",
      "--- Starting Real-Time Bot Detection Simulation ---\n",
      "\n",
      "Transaction 1:\n",
      "Predicted Bot Activity Probability: 0.3900\n",
      "Transaction appears legitimate. Proceeding with processing.\n",
      "\n",
      "Transaction 2:\n",
      "Predicted Bot Activity Probability: 0.3600\n",
      "Transaction appears legitimate. Proceeding with processing.\n",
      "\n",
      "Transaction 3:\n",
      "Predicted Bot Activity Probability: 0.3600\n",
      "Transaction appears legitimate. Proceeding with processing.\n",
      "\n",
      "Transaction 4:\n",
      "Predicted Bot Activity Probability: 0.3900\n",
      "Transaction appears legitimate. Proceeding with processing.\n",
      "\n",
      "Transaction 5:\n",
      "Predicted Bot Activity Probability: 0.3600\n",
      "Transaction appears legitimate. Proceeding with processing.\n",
      "\n",
      "Transaction 6:\n",
      "Predicted Bot Activity Probability: 0.3900\n",
      "Transaction appears legitimate. Proceeding with processing.\n",
      "\n",
      "Transaction 7:\n",
      "Predicted Bot Activity Probability: 0.3900\n",
      "Transaction appears legitimate. Proceeding with processing.\n",
      "\n",
      "Transaction 8:\n",
      "Predicted Bot Activity Probability: 0.3900\n",
      "Transaction appears legitimate. Proceeding with processing.\n",
      "\n",
      "Transaction 9:\n",
      "Predicted Bot Activity Probability: 0.3900\n",
      "Transaction appears legitimate. Proceeding with processing.\n",
      "\n",
      "Transaction 10:\n",
      "Predicted Bot Activity Probability: 0.3600\n",
      "Transaction appears legitimate. Proceeding with processing.\n",
      "\n",
      "--- Simulation Completed ---\n"
     ]
    }
   ],
   "source": [
    "# Run the real-time Bot detection monitoring simulation\n",
    "real_time_bot_detection(num_transactions=10, delay=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['bot_detection_features.joblib']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import joblib \n",
    "\n",
    "#save the feature columns \n",
    "\n",
    "joblib.dump(training_columns, 'bot_detection_features.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['bot_detection_model.joblib']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "\n",
    "# Save the trained model\n",
    "\n",
    "joblib.dump(pipeline, 'bot_detection_model.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "idk_gpu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
